# -*- coding: utf-8 -*-
"""Mnist-Logistic Regression (ML) ab8dbd

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/#fileId=https%3A//storage.googleapis.com/kaggle-colab-exported-notebooks/mnist-logistic-regression-ml-ab8dbd-a0497e6f-8e73-41ba-9be5-59d346138ad5.ipynb%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com/20241219/auto/storage/goog4_request%26X-Goog-Date%3D20241219T232857Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D503a59be8376c35847e34a3ded4fc694fb21c822123c551e97aef976d8e501ec015b227949c7453d9983f898c514bd4c7201e8f66b6a3281051a1e100253ac1634cbfa43b62ec9bfb4a2f468aa96064214563cd6101ff1849f5068ec1bd64c859576a00ae2b931e7091d7aba745d9ab30ec657cefd3dd1edf97248e22cab08ecd5b707bb3a313b388b69e6e583ad133ba4aa9fefe7bf6b5406e2761c544219b4149e13963a77679eea2ac18bb23c51b537867bc7d758d3e90f4b704530afa7e38b6112b464c0b4d7ad8316ba44fbb59f599df220118208cf6173db668d84d0670e4845664c9b2c676fab843c83e472c7fe04a30e97c50d993b930d86c67b1a42
"""

# Import necessary libraries
import torch
from torchvision import datasets #to find the dataset
from torchvision import transforms #to convert raw image data into a format suitable for training
import matplotlib.pyplot as plt #to visualize these images

# Define a transform to normalize the dataset
transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])

# Load the MNIST dataset
train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)
test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)

# Display dataset size
print(f"Number of training samples: {len(train_dataset)}")
print(f"Number of test samples: {len(test_dataset)}")

# Visualize some data samples
fig, ax = plt.subplots(1, 5, figsize=(10, 2))
for i in range(5):
    img, label = train_dataset[i]  # Get an image and its label
    ax[i].imshow(img.squeeze(), cmap="gray")  # Show the image
    ax[i].set_title(f"Label: {label}")  # Display the label
    ax[i].axis('off')  # Hide axes
plt.show()

import torch
import torch.nn as nn
import torch.optim as optim

# Define a simple logistic regression model
class LogisticRegressionModel(nn.Module):
    def __init__(self):
        super(LogisticRegressionModel, self).__init__()
        self.fc = nn.Linear(28 * 28, 10)  # 28x28 input to 10 output classes

    def forward(self, x):
        x = x.view(-1, 28 * 28)  # Flatten the input image to a 1D vector
        x = self.fc(x)  # Pass through the fully connected layer
        return x

# Initialize the model
model = LogisticRegressionModel()

# Loss function and optimizer
criterion = nn.CrossEntropyLoss()  # Cross-Entropy loss for multi-class classification
optimizer = optim.SGD(model.parameters(), lr=0.1)  # Stochastic Gradient Descent optimizer

# Training loop
epochs = 5  # Number of times to iterate over the dataset

train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)


for epoch in range(epochs):
    model.train()  # Set the model to training mode
    running_loss = 0.0

    for batch_idx, (data, target) in enumerate(train_loader):
        optimizer.zero_grad()  # Clear gradients before each step
        output = model(data)  # Forward pass
        loss = criterion(output, target)  # Compute the loss
        loss.backward()  # Backpropagation
        optimizer.step()  # Update model weights

        running_loss += loss.item()  # Keep track of the loss

    print(f"Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}")

# Evaluate the model
model.eval()  # Set the model to evaluation mode
correct = 0
total = 0

with torch.no_grad():  # Disable gradient calculation for inference
    for data, target in test_loader:
        output = model(data)
        _, predicted = torch.max(output, 1)  # Get the class with the highest probability
        total += target.size(0)
        correct += (predicted == target).sum().item()

accuracy = 100 * correct / total
print(f"Test Accuracy: {accuracy}%")